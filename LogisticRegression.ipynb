{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5136ec1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c6f26aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        \n",
    "    def sigmoid(self, Z):\n",
    "        return 1 / (1 + np.exp(-Z))\n",
    "    \n",
    "    def loss(self, y, y_pred):\n",
    "        return -(y*np.log(y_pred) + (1 - y)*np.log(1 - y_pred)).sum() / len(y)\n",
    "    \n",
    "    def fit(self, X, y, X_test, y_test, lr=0.001, epochs=100):\n",
    "        m, n = X.shape\n",
    "        y = y.reshape(m, 1)\n",
    "        y_test = y_test.reshape(y_test.shape[0], 1)\n",
    "        self.w = np.random.randn(n, 1)*0.001\n",
    "        self.b = np.random.randn()*0.001\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            Z = X.dot(self.w) + self.b\n",
    "            A = self.sigmoid(Z)\n",
    "            \n",
    "            dw = (X*(A-y)).sum(axis=0) / len(X)\n",
    "            db = (A-y).sum(axis=0) / len(X)\n",
    "            \n",
    "            self.w -= dw.reshape(n, 1)*lr\n",
    "            self.b -= db*lr\n",
    "            \n",
    "            predict = self.predict(X_test)\n",
    "            print('Epoch: {0}  Loss: {1:.2f}  Accuracy: {2:.2f}%'.format(epoch+1, self.loss(y_test, predict), ((predict > 0.5) == y_test).sum() / len(predict) * 100))\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return self.sigmoid(X.dot(self.w) + self.b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39849421",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_digits()\n",
    "X = data['data']\n",
    "y = (data['target'] >= 5).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94f3e396",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78fa3d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  Loss: 0.66  Accuracy: 71.11%\n",
      "Epoch: 2  Loss: 0.62  Accuracy: 79.72%\n",
      "Epoch: 3  Loss: 0.61  Accuracy: 68.06%\n",
      "Epoch: 4  Loss: 0.60  Accuracy: 60.83%\n",
      "Epoch: 5  Loss: 0.75  Accuracy: 49.17%\n",
      "Epoch: 6  Loss: 0.98  Accuracy: 51.67%\n",
      "Epoch: 7  Loss: 1.40  Accuracy: 48.33%\n",
      "Epoch: 8  Loss: 1.16  Accuracy: 51.67%\n",
      "Epoch: 9  Loss: 1.31  Accuracy: 48.33%\n",
      "Epoch: 10  Loss: 1.08  Accuracy: 51.67%\n",
      "Epoch: 11  Loss: 1.22  Accuracy: 48.89%\n",
      "Epoch: 12  Loss: 0.99  Accuracy: 52.22%\n",
      "Epoch: 13  Loss: 1.13  Accuracy: 49.72%\n",
      "Epoch: 14  Loss: 0.90  Accuracy: 53.89%\n",
      "Epoch: 15  Loss: 1.03  Accuracy: 51.11%\n",
      "Epoch: 16  Loss: 0.81  Accuracy: 55.56%\n",
      "Epoch: 17  Loss: 0.94  Accuracy: 55.56%\n",
      "Epoch: 18  Loss: 0.73  Accuracy: 58.89%\n",
      "Epoch: 19  Loss: 0.85  Accuracy: 57.50%\n",
      "Epoch: 20  Loss: 0.66  Accuracy: 62.50%\n",
      "Epoch: 21  Loss: 0.76  Accuracy: 60.00%\n",
      "Epoch: 22  Loss: 0.59  Accuracy: 65.83%\n",
      "Epoch: 23  Loss: 0.68  Accuracy: 64.44%\n",
      "Epoch: 24  Loss: 0.53  Accuracy: 70.83%\n",
      "Epoch: 25  Loss: 0.61  Accuracy: 67.78%\n",
      "Epoch: 26  Loss: 0.48  Accuracy: 73.89%\n",
      "Epoch: 27  Loss: 0.56  Accuracy: 73.06%\n",
      "Epoch: 28  Loss: 0.44  Accuracy: 77.22%\n",
      "Epoch: 29  Loss: 0.51  Accuracy: 77.50%\n",
      "Epoch: 30  Loss: 0.41  Accuracy: 79.44%\n",
      "Epoch: 31  Loss: 0.46  Accuracy: 78.33%\n",
      "Epoch: 32  Loss: 0.39  Accuracy: 81.67%\n",
      "Epoch: 33  Loss: 0.43  Accuracy: 79.44%\n",
      "Epoch: 34  Loss: 0.37  Accuracy: 84.17%\n",
      "Epoch: 35  Loss: 0.40  Accuracy: 81.11%\n",
      "Epoch: 36  Loss: 0.35  Accuracy: 85.28%\n",
      "Epoch: 37  Loss: 0.38  Accuracy: 82.50%\n",
      "Epoch: 38  Loss: 0.34  Accuracy: 86.39%\n",
      "Epoch: 39  Loss: 0.37  Accuracy: 84.72%\n",
      "Epoch: 40  Loss: 0.34  Accuracy: 86.39%\n",
      "Epoch: 41  Loss: 0.36  Accuracy: 84.72%\n",
      "Epoch: 42  Loss: 0.33  Accuracy: 86.67%\n",
      "Epoch: 43  Loss: 0.35  Accuracy: 84.17%\n",
      "Epoch: 44  Loss: 0.33  Accuracy: 87.22%\n",
      "Epoch: 45  Loss: 0.34  Accuracy: 85.00%\n",
      "Epoch: 46  Loss: 0.32  Accuracy: 88.33%\n",
      "Epoch: 47  Loss: 0.33  Accuracy: 85.83%\n",
      "Epoch: 48  Loss: 0.32  Accuracy: 88.33%\n",
      "Epoch: 49  Loss: 0.33  Accuracy: 85.83%\n",
      "Epoch: 50  Loss: 0.32  Accuracy: 88.06%\n",
      "Epoch: 51  Loss: 0.33  Accuracy: 86.39%\n",
      "Epoch: 52  Loss: 0.32  Accuracy: 86.94%\n",
      "Epoch: 53  Loss: 0.32  Accuracy: 86.67%\n",
      "Epoch: 54  Loss: 0.32  Accuracy: 87.22%\n",
      "Epoch: 55  Loss: 0.32  Accuracy: 86.94%\n",
      "Epoch: 56  Loss: 0.32  Accuracy: 87.22%\n",
      "Epoch: 57  Loss: 0.32  Accuracy: 86.94%\n",
      "Epoch: 58  Loss: 0.31  Accuracy: 87.22%\n",
      "Epoch: 59  Loss: 0.32  Accuracy: 86.67%\n",
      "Epoch: 60  Loss: 0.31  Accuracy: 87.50%\n",
      "Epoch: 61  Loss: 0.31  Accuracy: 86.67%\n",
      "Epoch: 62  Loss: 0.31  Accuracy: 87.78%\n",
      "Epoch: 63  Loss: 0.31  Accuracy: 87.50%\n",
      "Epoch: 64  Loss: 0.31  Accuracy: 87.78%\n",
      "Epoch: 65  Loss: 0.31  Accuracy: 87.50%\n",
      "Epoch: 66  Loss: 0.31  Accuracy: 87.78%\n",
      "Epoch: 67  Loss: 0.31  Accuracy: 87.50%\n",
      "Epoch: 68  Loss: 0.31  Accuracy: 87.78%\n",
      "Epoch: 69  Loss: 0.31  Accuracy: 87.50%\n",
      "Epoch: 70  Loss: 0.31  Accuracy: 87.50%\n",
      "Epoch: 71  Loss: 0.31  Accuracy: 87.50%\n",
      "Epoch: 72  Loss: 0.31  Accuracy: 87.22%\n",
      "Epoch: 73  Loss: 0.31  Accuracy: 87.22%\n",
      "Epoch: 74  Loss: 0.31  Accuracy: 87.22%\n",
      "Epoch: 75  Loss: 0.30  Accuracy: 86.94%\n",
      "Epoch: 76  Loss: 0.30  Accuracy: 86.94%\n",
      "Epoch: 77  Loss: 0.30  Accuracy: 86.94%\n",
      "Epoch: 78  Loss: 0.30  Accuracy: 86.94%\n",
      "Epoch: 79  Loss: 0.30  Accuracy: 87.22%\n",
      "Epoch: 80  Loss: 0.30  Accuracy: 87.22%\n",
      "Epoch: 81  Loss: 0.30  Accuracy: 87.22%\n",
      "Epoch: 82  Loss: 0.30  Accuracy: 87.22%\n",
      "Epoch: 83  Loss: 0.30  Accuracy: 87.22%\n",
      "Epoch: 84  Loss: 0.30  Accuracy: 87.22%\n",
      "Epoch: 85  Loss: 0.30  Accuracy: 87.22%\n",
      "Epoch: 86  Loss: 0.30  Accuracy: 87.50%\n",
      "Epoch: 87  Loss: 0.30  Accuracy: 87.50%\n",
      "Epoch: 88  Loss: 0.30  Accuracy: 87.50%\n",
      "Epoch: 89  Loss: 0.30  Accuracy: 87.50%\n",
      "Epoch: 90  Loss: 0.30  Accuracy: 87.50%\n",
      "Epoch: 91  Loss: 0.30  Accuracy: 87.50%\n",
      "Epoch: 92  Loss: 0.30  Accuracy: 87.50%\n",
      "Epoch: 93  Loss: 0.30  Accuracy: 87.50%\n",
      "Epoch: 94  Loss: 0.30  Accuracy: 87.50%\n",
      "Epoch: 95  Loss: 0.29  Accuracy: 87.50%\n",
      "Epoch: 96  Loss: 0.29  Accuracy: 87.50%\n",
      "Epoch: 97  Loss: 0.29  Accuracy: 87.50%\n",
      "Epoch: 98  Loss: 0.29  Accuracy: 87.50%\n",
      "Epoch: 99  Loss: 0.29  Accuracy: 87.50%\n",
      "Epoch: 100  Loss: 0.29  Accuracy: 87.50%\n",
      "Epoch: 101  Loss: 0.29  Accuracy: 87.50%\n",
      "Epoch: 102  Loss: 0.29  Accuracy: 87.50%\n",
      "Epoch: 103  Loss: 0.29  Accuracy: 87.50%\n",
      "Epoch: 104  Loss: 0.29  Accuracy: 87.50%\n",
      "Epoch: 105  Loss: 0.29  Accuracy: 87.50%\n",
      "Epoch: 106  Loss: 0.29  Accuracy: 87.50%\n",
      "Epoch: 107  Loss: 0.29  Accuracy: 87.50%\n",
      "Epoch: 108  Loss: 0.29  Accuracy: 87.50%\n",
      "Epoch: 109  Loss: 0.29  Accuracy: 87.50%\n",
      "Epoch: 110  Loss: 0.29  Accuracy: 87.50%\n",
      "Epoch: 111  Loss: 0.29  Accuracy: 87.50%\n",
      "Epoch: 112  Loss: 0.29  Accuracy: 87.50%\n",
      "Epoch: 113  Loss: 0.29  Accuracy: 87.50%\n",
      "Epoch: 114  Loss: 0.29  Accuracy: 87.50%\n",
      "Epoch: 115  Loss: 0.29  Accuracy: 87.50%\n",
      "Epoch: 116  Loss: 0.29  Accuracy: 87.50%\n",
      "Epoch: 117  Loss: 0.29  Accuracy: 87.50%\n",
      "Epoch: 118  Loss: 0.29  Accuracy: 87.50%\n",
      "Epoch: 119  Loss: 0.29  Accuracy: 87.50%\n",
      "Epoch: 120  Loss: 0.29  Accuracy: 87.50%\n",
      "Epoch: 121  Loss: 0.29  Accuracy: 87.50%\n",
      "Epoch: 122  Loss: 0.28  Accuracy: 87.50%\n",
      "Epoch: 123  Loss: 0.28  Accuracy: 87.50%\n",
      "Epoch: 124  Loss: 0.28  Accuracy: 87.50%\n",
      "Epoch: 125  Loss: 0.28  Accuracy: 87.50%\n",
      "Epoch: 126  Loss: 0.28  Accuracy: 87.78%\n",
      "Epoch: 127  Loss: 0.28  Accuracy: 87.78%\n",
      "Epoch: 128  Loss: 0.28  Accuracy: 87.78%\n",
      "Epoch: 129  Loss: 0.28  Accuracy: 87.78%\n",
      "Epoch: 130  Loss: 0.28  Accuracy: 87.78%\n",
      "Epoch: 131  Loss: 0.28  Accuracy: 87.78%\n",
      "Epoch: 132  Loss: 0.28  Accuracy: 87.78%\n",
      "Epoch: 133  Loss: 0.28  Accuracy: 87.78%\n",
      "Epoch: 134  Loss: 0.28  Accuracy: 87.78%\n",
      "Epoch: 135  Loss: 0.28  Accuracy: 87.78%\n",
      "Epoch: 136  Loss: 0.28  Accuracy: 87.78%\n",
      "Epoch: 137  Loss: 0.28  Accuracy: 87.78%\n",
      "Epoch: 138  Loss: 0.28  Accuracy: 87.78%\n",
      "Epoch: 139  Loss: 0.28  Accuracy: 87.78%\n",
      "Epoch: 140  Loss: 0.28  Accuracy: 87.78%\n",
      "Epoch: 141  Loss: 0.28  Accuracy: 87.78%\n",
      "Epoch: 142  Loss: 0.28  Accuracy: 87.78%\n",
      "Epoch: 143  Loss: 0.28  Accuracy: 87.78%\n",
      "Epoch: 144  Loss: 0.28  Accuracy: 87.78%\n",
      "Epoch: 145  Loss: 0.28  Accuracy: 87.78%\n",
      "Epoch: 146  Loss: 0.28  Accuracy: 87.78%\n",
      "Epoch: 147  Loss: 0.28  Accuracy: 87.78%\n",
      "Epoch: 148  Loss: 0.28  Accuracy: 87.78%\n",
      "Epoch: 149  Loss: 0.28  Accuracy: 87.78%\n",
      "Epoch: 150  Loss: 0.28  Accuracy: 87.50%\n",
      "Epoch: 151  Loss: 0.28  Accuracy: 87.50%\n",
      "Epoch: 152  Loss: 0.28  Accuracy: 87.50%\n",
      "Epoch: 153  Loss: 0.28  Accuracy: 87.50%\n",
      "Epoch: 154  Loss: 0.28  Accuracy: 87.50%\n",
      "Epoch: 155  Loss: 0.28  Accuracy: 87.78%\n",
      "Epoch: 156  Loss: 0.28  Accuracy: 87.78%\n",
      "Epoch: 157  Loss: 0.28  Accuracy: 87.78%\n",
      "Epoch: 158  Loss: 0.28  Accuracy: 87.78%\n",
      "Epoch: 159  Loss: 0.28  Accuracy: 87.78%\n",
      "Epoch: 160  Loss: 0.28  Accuracy: 87.78%\n",
      "Epoch: 161  Loss: 0.27  Accuracy: 87.78%\n",
      "Epoch: 162  Loss: 0.27  Accuracy: 87.78%\n",
      "Epoch: 163  Loss: 0.27  Accuracy: 87.78%\n",
      "Epoch: 164  Loss: 0.27  Accuracy: 87.78%\n",
      "Epoch: 165  Loss: 0.27  Accuracy: 87.78%\n",
      "Epoch: 166  Loss: 0.27  Accuracy: 87.78%\n",
      "Epoch: 167  Loss: 0.27  Accuracy: 87.78%\n",
      "Epoch: 168  Loss: 0.27  Accuracy: 87.78%\n",
      "Epoch: 169  Loss: 0.27  Accuracy: 87.78%\n",
      "Epoch: 170  Loss: 0.27  Accuracy: 87.78%\n",
      "Epoch: 171  Loss: 0.27  Accuracy: 87.78%\n",
      "Epoch: 172  Loss: 0.27  Accuracy: 87.78%\n",
      "Epoch: 173  Loss: 0.27  Accuracy: 87.78%\n",
      "Epoch: 174  Loss: 0.27  Accuracy: 87.78%\n",
      "Epoch: 175  Loss: 0.27  Accuracy: 87.78%\n",
      "Epoch: 176  Loss: 0.27  Accuracy: 87.78%\n",
      "Epoch: 177  Loss: 0.27  Accuracy: 87.78%\n",
      "Epoch: 178  Loss: 0.27  Accuracy: 87.78%\n",
      "Epoch: 179  Loss: 0.27  Accuracy: 87.78%\n",
      "Epoch: 180  Loss: 0.27  Accuracy: 87.78%\n",
      "Epoch: 181  Loss: 0.27  Accuracy: 87.78%\n",
      "Epoch: 182  Loss: 0.27  Accuracy: 87.78%\n",
      "Epoch: 183  Loss: 0.27  Accuracy: 88.06%\n",
      "Epoch: 184  Loss: 0.27  Accuracy: 88.06%\n",
      "Epoch: 185  Loss: 0.27  Accuracy: 88.06%\n",
      "Epoch: 186  Loss: 0.27  Accuracy: 88.06%\n",
      "Epoch: 187  Loss: 0.27  Accuracy: 88.06%\n",
      "Epoch: 188  Loss: 0.27  Accuracy: 88.06%\n",
      "Epoch: 189  Loss: 0.27  Accuracy: 88.06%\n",
      "Epoch: 190  Loss: 0.27  Accuracy: 88.06%\n",
      "Epoch: 191  Loss: 0.27  Accuracy: 88.06%\n",
      "Epoch: 192  Loss: 0.27  Accuracy: 88.06%\n",
      "Epoch: 193  Loss: 0.27  Accuracy: 88.06%\n",
      "Epoch: 194  Loss: 0.27  Accuracy: 88.33%\n",
      "Epoch: 195  Loss: 0.27  Accuracy: 88.61%\n",
      "Epoch: 196  Loss: 0.27  Accuracy: 88.61%\n",
      "Epoch: 197  Loss: 0.27  Accuracy: 88.89%\n",
      "Epoch: 198  Loss: 0.27  Accuracy: 88.89%\n",
      "Epoch: 199  Loss: 0.27  Accuracy: 88.89%\n",
      "Epoch: 200  Loss: 0.27  Accuracy: 88.89%\n",
      "Epoch: 201  Loss: 0.27  Accuracy: 88.89%\n",
      "Epoch: 202  Loss: 0.27  Accuracy: 88.89%\n",
      "Epoch: 203  Loss: 0.27  Accuracy: 88.89%\n",
      "Epoch: 204  Loss: 0.27  Accuracy: 88.89%\n",
      "Epoch: 205  Loss: 0.27  Accuracy: 88.89%\n",
      "Epoch: 206  Loss: 0.27  Accuracy: 88.89%\n",
      "Epoch: 207  Loss: 0.27  Accuracy: 88.89%\n",
      "Epoch: 208  Loss: 0.27  Accuracy: 88.89%\n",
      "Epoch: 209  Loss: 0.27  Accuracy: 88.89%\n",
      "Epoch: 210  Loss: 0.27  Accuracy: 89.17%\n",
      "Epoch: 211  Loss: 0.27  Accuracy: 89.17%\n",
      "Epoch: 212  Loss: 0.27  Accuracy: 89.17%\n",
      "Epoch: 213  Loss: 0.27  Accuracy: 89.17%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 214  Loss: 0.27  Accuracy: 89.17%\n",
      "Epoch: 215  Loss: 0.27  Accuracy: 89.17%\n",
      "Epoch: 216  Loss: 0.27  Accuracy: 89.17%\n",
      "Epoch: 217  Loss: 0.27  Accuracy: 89.17%\n",
      "Epoch: 218  Loss: 0.27  Accuracy: 89.17%\n",
      "Epoch: 219  Loss: 0.27  Accuracy: 89.17%\n",
      "Epoch: 220  Loss: 0.27  Accuracy: 89.17%\n",
      "Epoch: 221  Loss: 0.27  Accuracy: 89.17%\n",
      "Epoch: 222  Loss: 0.26  Accuracy: 89.44%\n",
      "Epoch: 223  Loss: 0.26  Accuracy: 89.44%\n",
      "Epoch: 224  Loss: 0.26  Accuracy: 89.44%\n",
      "Epoch: 225  Loss: 0.26  Accuracy: 89.44%\n",
      "Epoch: 226  Loss: 0.26  Accuracy: 89.44%\n",
      "Epoch: 227  Loss: 0.26  Accuracy: 89.44%\n",
      "Epoch: 228  Loss: 0.26  Accuracy: 89.44%\n",
      "Epoch: 229  Loss: 0.26  Accuracy: 89.44%\n",
      "Epoch: 230  Loss: 0.26  Accuracy: 89.44%\n",
      "Epoch: 231  Loss: 0.26  Accuracy: 89.44%\n",
      "Epoch: 232  Loss: 0.26  Accuracy: 89.44%\n",
      "Epoch: 233  Loss: 0.26  Accuracy: 89.44%\n",
      "Epoch: 234  Loss: 0.26  Accuracy: 89.44%\n",
      "Epoch: 235  Loss: 0.26  Accuracy: 89.44%\n",
      "Epoch: 236  Loss: 0.26  Accuracy: 89.44%\n",
      "Epoch: 237  Loss: 0.26  Accuracy: 89.44%\n",
      "Epoch: 238  Loss: 0.26  Accuracy: 89.44%\n",
      "Epoch: 239  Loss: 0.26  Accuracy: 89.44%\n",
      "Epoch: 240  Loss: 0.26  Accuracy: 89.44%\n",
      "Epoch: 241  Loss: 0.26  Accuracy: 89.44%\n",
      "Epoch: 242  Loss: 0.26  Accuracy: 89.44%\n",
      "Epoch: 243  Loss: 0.26  Accuracy: 89.44%\n",
      "Epoch: 244  Loss: 0.26  Accuracy: 89.44%\n",
      "Epoch: 245  Loss: 0.26  Accuracy: 89.44%\n",
      "Epoch: 246  Loss: 0.26  Accuracy: 89.44%\n",
      "Epoch: 247  Loss: 0.26  Accuracy: 89.44%\n",
      "Epoch: 248  Loss: 0.26  Accuracy: 89.44%\n",
      "Epoch: 249  Loss: 0.26  Accuracy: 89.44%\n",
      "Epoch: 250  Loss: 0.26  Accuracy: 89.44%\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train, X_test, y_test, lr=0.005, epochs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15c33c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict:  [0.17475798] no \n",
      "digit:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 0\n",
    "img = data['data'][n]\n",
    "predict = model.predict(img)\n",
    "print(\"predict: \", predict, \"no\" if predict < 0.5 else \"yes\", \"\\ndigit: \", data['target'][n])\n",
    "plt.imshow(img.reshape((8, 8)), cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4993d1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
